{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj9Q5rZAFAlM"
   },
   "source": [
    "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
    "--- | ---\n",
    "Course Code: | CPE 313\n",
    "Code Title: | Advanced Machine Learning and Deep Learning\n",
    "2nd Semester | AY 2024-2025\n",
    "<u>**ACTIVITY NO. 7** | **Performing Face Recognition**\n",
    "**Name** | Cu, Angelo Luis\n",
    "**Section** | CPE32S3\n",
    "**Date Performed**: | 2/20/2025\n",
    "**Date Submitted**: | 2/21/2025\n",
    "**Instructor**: | Engr. Roman M. Richard\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElMxAUPJGYLw"
   },
   "source": [
    "## 1. Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr0bUEs1nxE0"
   },
   "source": [
    "This activity aims to enable students to perform data preparation and face recognition on their own generated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "do-8nSpXFpyd"
   },
   "source": [
    "## 2. Intended Learning Outcomes (ILOs)\n",
    "After this activity, the students should be able to:\n",
    "* Utilize data preparation techniques for images.\n",
    "* Perform Face Recognition using multiple algorithms.\n",
    "* Evaluate the performance of different algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-RNZovNGV9k"
   },
   "source": [
    "## 3. Procedures and Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBQh8Eyf1EHC"
   },
   "source": [
    "### Preparing the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpAAiS_V1Jfy"
   },
   "source": [
    "Now that we have our data, we need to load these sample pictures into our face recognition algorithms. All face recognition algorithms take two parameters in their `train()` method: an array of images and an array of labels. What do these labels represent? They are the IDs of a certain individual/face so that when face recognition is performed, we not only know the person was recognized but also who—among the many people available in our database—the person is.\n",
    "\n",
    "To do that, we need to create a comma-separated value (CSV) file, which will contain the path to a sample picture followed by the ID of that person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWqIq9Sz1Svi"
   },
   "source": [
    "**Include a Screenshot of Your Dataset Here**\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SiR2yJQ1W7B"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPA3SGHN1YdC"
   },
   "source": [
    "### Loading the data and recognizing faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q07mfdMq1b2J"
   },
   "source": [
    "Next up, we need to load these two resources (the array of images and CSV file) into the face recognition algorithm, so it can be trained to recognize our face. To do this, we build a function that reads the CSV file and—for each line of the file—loads the image at the corresponding path into the images array and the ID into the labels array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c4TmUw_BEeUc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import errno\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "def read_images(path, sz=None):\n",
    "  c = 0\n",
    "  X, y = [], []\n",
    "\n",
    "  for dirname, dirnames, filenames in os.walk(path):\n",
    "    for subdirname in dirnames:\n",
    "      subject_path = os.path.join(dirname, subdirname)\n",
    "      for filename in os.listdir(subject_path):\n",
    "        try:\n",
    "          if(filename == \".directory\"):\n",
    "            continue\n",
    "          filepath = os.path.join(subject_path, filename)\n",
    "          im = cv2.imread(os.path.join(subject_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "          # Resize the images to the prescribed size\n",
    "          if (sz is not None):\n",
    "            im = cv2.resize(im, (200,200))\n",
    "\n",
    "          X.append(np.asarray(im, dtype=np.uint8))\n",
    "          y.append(c)\n",
    "\n",
    "        except IOError as e:\n",
    "          print(f\"I/O Error({e.errno}): {e.strerror}\")\n",
    "        except:\n",
    "          print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "          raise\n",
    "      c = c+1\n",
    "  return [X, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[199, 200, 200, ..., 174, 175, 173],\n",
      "       [200, 200, 200, ..., 174, 175, 173],\n",
      "       [201, 200, 200, ..., 175, 175, 174],\n",
      "       ...,\n",
      "       [131, 132, 132, ..., 198, 198, 199],\n",
      "       [131, 132, 132, ..., 198, 198, 199],\n",
      "       [131, 133, 132, ..., 199, 199, 200]], dtype=uint8), array([[214, 215, 213, ..., 147, 146, 146],\n",
      "       [213, 213, 211, ..., 148, 147, 147],\n",
      "       [213, 212, 211, ..., 150, 150, 151],\n",
      "       ...,\n",
      "       [161, 161, 161, ...,  82,  82,  83],\n",
      "       [161, 162, 162, ...,  82,  84,  84],\n",
      "       [162, 163, 162, ...,  77,  81,  83]], dtype=uint8), array([[197, 198, 198, ..., 169, 168, 168],\n",
      "       [198, 198, 198, ..., 170, 171, 171],\n",
      "       [198, 198, 198, ..., 170, 172, 172],\n",
      "       ...,\n",
      "       [139, 139, 139, ..., 200, 199, 200],\n",
      "       [138, 139, 138, ..., 199, 199, 201],\n",
      "       [136, 138, 137, ..., 199, 199, 201]], dtype=uint8), array([[224, 226, 228, ..., 179, 178, 176],\n",
      "       [225, 226, 227, ..., 179, 176, 174],\n",
      "       [227, 227, 228, ..., 178, 175, 174],\n",
      "       ...,\n",
      "       [181, 182, 184, ..., 161, 160, 160],\n",
      "       [181, 181, 183, ..., 158, 157, 156],\n",
      "       [180, 180, 182, ..., 156, 155, 152]], dtype=uint8), array([[229, 229, 228, ..., 180, 179, 177],\n",
      "       [230, 229, 229, ..., 181, 180, 178],\n",
      "       [229, 229, 229, ..., 181, 180, 179],\n",
      "       ...,\n",
      "       [166, 167, 166, ..., 148, 152, 157],\n",
      "       [166, 167, 166, ..., 151, 154, 160],\n",
      "       [167, 167, 167, ..., 156, 157, 161]], dtype=uint8), array([[208, 208, 209, ..., 163, 160, 153],\n",
      "       [205, 205, 206, ..., 163, 162, 159],\n",
      "       [207, 206, 206, ..., 160, 160, 160],\n",
      "       ...,\n",
      "       [111, 111, 110, ...,  36,  35,  32],\n",
      "       [110, 111, 111, ...,  35,  33,  30],\n",
      "       [110, 111, 112, ...,  33,  31,  29]], dtype=uint8), array([[239, 240, 241, ..., 188, 190, 191],\n",
      "       [241, 241, 241, ..., 188, 189, 190],\n",
      "       [242, 241, 241, ..., 187, 188, 189],\n",
      "       ...,\n",
      "       [165, 167, 170, ..., 204, 204, 204],\n",
      "       [167, 169, 172, ..., 203, 203, 203],\n",
      "       [169, 170, 173, ..., 203, 203, 203]], dtype=uint8), array([[237, 238, 240, ..., 179, 180, 180],\n",
      "       [239, 239, 240, ..., 181, 182, 183],\n",
      "       [241, 241, 240, ..., 181, 182, 183],\n",
      "       ...,\n",
      "       [210, 209, 208, ..., 197, 198, 199],\n",
      "       [210, 209, 209, ..., 196, 197, 198],\n",
      "       [210, 209, 209, ..., 195, 196, 197]], dtype=uint8), array([[240, 241, 242, ..., 184, 185, 186],\n",
      "       [240, 240, 241, ..., 184, 185, 186],\n",
      "       [240, 240, 240, ..., 184, 185, 186],\n",
      "       ...,\n",
      "       [210, 210, 209, ..., 203, 203, 203],\n",
      "       [210, 210, 210, ..., 202, 202, 202],\n",
      "       [210, 211, 210, ..., 202, 202, 202]], dtype=uint8), array([[197, 198, 200, ..., 148, 145, 140],\n",
      "       [198, 197, 198, ..., 148, 146, 143],\n",
      "       [199, 195, 195, ..., 149, 147, 144],\n",
      "       ...,\n",
      "       [163, 164, 163, ...,  87,  87,  85],\n",
      "       [164, 165, 165, ...,  88,  88,  90],\n",
      "       [166, 166, 167, ...,  84,  86,  91]], dtype=uint8), array([[199, 198, 198, ..., 188, 189, 189],\n",
      "       [198, 198, 198, ..., 186, 188, 189],\n",
      "       [198, 198, 198, ..., 185, 186, 187],\n",
      "       ...,\n",
      "       [ 65,  61,  60, ...,  69,  71,  72],\n",
      "       [ 67,  61,  59, ...,  66,  68,  71],\n",
      "       [ 64,  59,  57, ...,  66,  68,  70]], dtype=uint8), array([[208, 207, 207, ..., 202, 201, 200],\n",
      "       [208, 207, 206, ..., 202, 200, 199],\n",
      "       [208, 206, 206, ..., 202, 201, 199],\n",
      "       ...,\n",
      "       [ 78,  79,  80, ...,  90,  89,  90],\n",
      "       [ 75,  78,  80, ...,  89,  89,  88],\n",
      "       [ 74,  79,  82, ...,  90,  90,  89]], dtype=uint8), array([[200, 199, 198, ..., 180, 180, 181],\n",
      "       [201, 199, 198, ..., 180, 180, 181],\n",
      "       [201, 199, 197, ..., 180, 181, 182],\n",
      "       ...,\n",
      "       [ 51,  51,  50, ...,  61,  61,  62],\n",
      "       [ 50,  50,  50, ...,  61,  61,  63],\n",
      "       [ 53,  51,  52, ...,  61,  60,  61]], dtype=uint8), array([[191, 192, 194, ..., 157, 157, 158],\n",
      "       [193, 193, 195, ..., 158, 157, 157],\n",
      "       [193, 194, 195, ..., 159, 157, 157],\n",
      "       ...,\n",
      "       [ 54,  52,  52, ...,  52,  53,  55],\n",
      "       [ 55,  54,  54, ...,  54,  53,  53],\n",
      "       [ 55,  55,  56, ...,  56,  55,  54]], dtype=uint8), array([[223, 224, 223, ..., 191, 193, 195],\n",
      "       [223, 223, 223, ..., 191, 193, 194],\n",
      "       [222, 223, 223, ..., 193, 194, 194],\n",
      "       ...,\n",
      "       [ 71,  67,  67, ...,  79,  81,  80],\n",
      "       [ 72,  68,  68, ...,  81,  82,  82],\n",
      "       [ 74,  70,  71, ...,  82,  82,  81]], dtype=uint8), array([[218, 220, 220, ..., 189, 188, 188],\n",
      "       [218, 219, 220, ..., 189, 189, 189],\n",
      "       [218, 219, 219, ..., 187, 188, 188],\n",
      "       ...,\n",
      "       [ 69,  70,  72, ...,  84,  84,  83],\n",
      "       [ 69,  69,  69, ...,  80,  81,  83],\n",
      "       [ 69,  68,  66, ...,  78,  78,  80]], dtype=uint8), array([[204, 203, 202, ..., 165, 166, 166],\n",
      "       [205, 204, 204, ..., 167, 167, 166],\n",
      "       [204, 204, 204, ..., 169, 169, 166],\n",
      "       ...,\n",
      "       [ 50,  51,  49, ...,  53,  52,  58],\n",
      "       [ 50,  51,  49, ...,  59,  57,  60],\n",
      "       [ 50,  51,  51, ...,  63,  62,  65]], dtype=uint8), array([[197, 199, 202, ..., 174, 173, 173],\n",
      "       [198, 200, 201, ..., 174, 174, 175],\n",
      "       [201, 201, 200, ..., 174, 174, 176],\n",
      "       ...,\n",
      "       [ 58,  60,  60, ...,  62,  63,  70],\n",
      "       [ 55,  58,  60, ...,  65,  65,  70],\n",
      "       [ 57,  58,  57, ...,  71,  69,  70]], dtype=uint8), array([[254, 254, 254, ..., 222, 222, 221],\n",
      "       [254, 254, 254, ..., 222, 222, 222],\n",
      "       [254, 254, 255, ..., 222, 222, 222],\n",
      "       ...,\n",
      "       [113, 113, 113, ..., 104, 103, 104],\n",
      "       [111, 111, 111, ..., 103, 102, 103],\n",
      "       [112, 111, 110, ..., 101, 100, 101]], dtype=uint8), array([[227, 228, 230, ..., 206, 205, 205],\n",
      "       [227, 228, 230, ..., 206, 205, 205],\n",
      "       [227, 228, 230, ..., 207, 205, 205],\n",
      "       ...,\n",
      "       [ 86,  86,  87, ...,  70,  71,  72],\n",
      "       [ 89,  88,  88, ...,  70,  70,  71],\n",
      "       [ 93,  91,  89, ...,  71,  71,  72]], dtype=uint8)], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "test_data = read_images(\"dataset\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWNBxCbO2oO-"
   },
   "source": [
    "**Question: Run the function above on your generated dataset. Provide an analysis and note all the challenges you have encountered running this code.**\n",
    "\n",
    "The function only takes the filepath of the dataset, with the dataset folder containing subfolders of people we want to detect. These subfolders would then contain the images themselves, with the function then converting these images into arrays of numbers with labels which is used by the machine learning model later. The challenge that I encountered in running the code is understanding how the file system should work for the dataset to be converted properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJ5IMZcC3wZt"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlLWfyvY3xm0"
   },
   "source": [
    "### Performing Face Recognition Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVF9dfTQ30pc"
   },
   "source": [
    "Here is a sample script for testing the Face Recognition Algorithm. In this section, we're going to follow the same process but with different algorithms for face recognitions, namely:\n",
    "- Eigenface Recognition\n",
    "- Fisherface Recognition\n",
    "- Local Binary Pattern Histograms (LBPH) Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cYQ19foI4Oe7"
   },
   "outputs": [],
   "source": [
    "def face_rec():\n",
    "  names = ['Sibling', 'Me'] # Put your names here for faces to recognize\n",
    "  if len(sys.argv) < 2:\n",
    "    print(\"USAGE: facerec_demo.py </path/to/images> [</path/to/store/images/at>]\")\n",
    "    sys.exit()\n",
    "\n",
    "  [X, y] = read_images(\"dataset\", (200,200)) # modified sys.argv[1] to dataset path\n",
    "  y = np.asarray(y, dtype=np.int32)\n",
    "\n",
    "  model = cv2.face.EigenFaceRecognizer_create()\n",
    "  model.train(X, y)\n",
    "\n",
    "  camera = cv2.VideoCapture(0)\n",
    "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "  while True:\n",
    "    ret, img = camera.read()\n",
    "    if not ret:\n",
    "      break\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "      cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "      gray = cv2.cvtColor(img[y:y + h, x:x + w], cv2.COLOR_BGR2GRAY)\n",
    "      roi = cv2.resize(gray, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "      try:\n",
    "        params = model.predict(roi)\n",
    "        label = names[params[0]]\n",
    "        cv2.putText(img, label + \", \" + str(params[1]), (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "    cv2.imshow(\"camera\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "      break\n",
    "\n",
    "  camera.release()\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  face_rec()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\cu\\appdata\\roaming\\python\\python311\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\cu\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iChhyN_Y4OH7"
   },
   "source": [
    "**Question: Provide an analysis of the sample script for the process using the Eigenface Model. What is the sample code doing? Are you able to troubleshoot any problems encountered?**\n",
    "\n",
    "The script is similar to the face detection code provided under Activity 6, with the difference being an addition of the training of a face classifier in the try except portion, with the input being the dataset of images while the output is the classified label of the face with its confidence.\n",
    "\n",
    "The first error I encountered is the cv2 not having the `face` module, which was resolved by installing the appropriate library `opencv-contrib-python`\n",
    "\n",
    "The second error I encountered is that the sizes from trained model and the camera for detection is not the same, which is why the faces are not classified. It is solved by changing the `sz` parameter of `read_images` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dL7n-mc5JO6"
   },
   "source": [
    "---\n",
    "Perform the remaining face recognition techniques by using the same (or modified) process from the sample code:\n",
    "\n",
    "- `model = cv2.face.createFisherFaceRecognizer()`\n",
    "- `model = cv2.face.createLBPHFaceRecognizer()`\n",
    "\n",
    "Modifying the code, we change the line `model = cv2.face.EigenFaceRecognizer_create()`\n",
    "\n",
    "to either `cv2.face.FisherFaceRecognizer_create()` or `cv2.face.LBPHFaceRecognizer_create()` as their correct syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb6Zeh9S5Y1o"
   },
   "source": [
    "**Question: The `predict()` method returns a two-element array. Provide your analysis of the two returned values and their important ince this application.**\n",
    "\n",
    "The two values returned by the predict() method according to the documentation (https://docs.opencv.org/3.4/dd/d65/classcv_1_1face_1_1FaceRecognizer.html#ab0d593e53ebd9a0f350c989fcac7f251) are the label and the confidence of the model of its label. It is important since the model might misclassify people, and therefore we can set the confidence level before labelling a particular face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkyd0KjtGl79"
   },
   "source": [
    "## 4. Supplementary Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zgo4nuQt506X"
   },
   "source": [
    "Your accomplisment of the tasks below contribute to the achievement of ILO1, ILO2, and ILO3 for this module.\n",
    "\n",
    "---\n",
    "\n",
    "Tasks:\n",
    "1. Create a new dataset for testing, this dataset must include the following:\n",
    "  - The same person/s that the model has to recognize.\n",
    "  - Different person/s that the model should not recognize.\n",
    "2. For each model, perform 20 tests. Document the testing performed and provide observations.\n",
    "3. Conclude on the performed tests by providing your evaluation of the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_rec(filepath, model):\n",
    "  names = ['Person1', 'Person2'] # Put your names here for faces to recognize\n",
    "\n",
    "  [X, y] = read_images(filepath, (200,200))\n",
    "  y = np.asarray(y, dtype=np.int32)\n",
    "\n",
    "  model.train(X, y)\n",
    "\n",
    "  camera = cv2.VideoCapture(0)\n",
    "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "  while True:\n",
    "    ret, img = camera.read()\n",
    "    if not ret:\n",
    "      break\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "      cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "      gray = cv2.cvtColor(img[y:y + h, x:x + w], cv2.COLOR_BGR2GRAY)\n",
    "      roi = cv2.resize(gray, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "      try:\n",
    "        params = model.predict(roi)\n",
    "        label = names[params[0]] \n",
    "        if label == \"Person2\":\n",
    "          cv2.putText(img, \"Recognized Person\", (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        else:\n",
    "          cv2.putText(img, \"Unknown Person\", (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "    cv2.imshow(\"camera\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "      break\n",
    "\n",
    "  camera.release()\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#  face_rec()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of models\n",
    "model1 = cv2.face.EigenFaceRecognizer_create()\n",
    "model2 = cv2.face.FisherFaceRecognizer_create()\n",
    "model3 = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Performing face recognition using EigenFaces model\n",
    "face_rec(\"dataset\", model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing face recognition using FisherFaces model\n",
    "face_rec(\"dataset\", model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing face recognition using LBPHFaces model\n",
    "face_rec(\"dataset\", model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answers for questions 2 to 3 are saved in a google docs file with the link: https://docs.google.com/document/d/1-jIIiJnK3Bw6Vt0dNwLw5vOU1_fbQoG9SS6xXxhkG4o/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQspxP0IGoO1"
   },
   "source": [
    "## 5. Summary, Conclusions and Lessons Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvcmGICAoj1a"
   },
   "source": [
    "In conclusion, I have learned how to perform face recognition by using different models available on OpenCV. I also applied data collection from the first Data Science course to create a dataset for images, which is then converted to an array of numbers with labels. Finally, after testing the three models with my custom dataset, the best for classification is the FisherFaces model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqlVIPSqolAC"
   },
   "source": [
    "<hr/>\n",
    "\n",
    "***Proprietary Clause***\n",
    "\n",
    "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ElMxAUPJGYLw",
    "X-RNZovNGV9k",
    "Mkyd0KjtGl79",
    "KQspxP0IGoO1"
   ],
   "provenance": [
    {
     "file_id": "10PkM873GcAtn-v_NQO81yw-qwCcE34Y-",
     "timestamp": 1739795927685
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
